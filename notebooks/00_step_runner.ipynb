{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8adb603a",
   "metadata": {},
   "source": [
    "# Inkswarm DetectLab — Step Runner Notebook (D-0022+)\n",
    "\n",
    "Run the pipeline step-by-step with **clear visibility**, **artifact reuse**, and **restart safety**.\n",
    "\n",
    "## Steps\n",
    "0. Bootstrap & Imports\n",
    "1. Wiring / paths check (dry-run)\n",
    "2. Dataset (raw + splits) — compute or reuse\n",
    "3. Labels + sanity checks (lightweight)\n",
    "4. Features — compute or reuse (shared cache optional)\n",
    "5. Baselines — compute or reuse\n",
    "6. Eval — slice + stability reports\n",
    "7. Export — UI summary, exec summary, UI bundle, handover, (optional) evidence\n",
    "8. Step summary (latest attempt per step)\n",
    "\n",
    "> **Tip:** Run cells top-to-bottom. If you restart the kernel, rerun from the top.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6f3e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0A — Bootstrap: locate repo root + config path robustly\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def _find_repo_root(start: Path | None = None) -> Path:\n",
    "    p = (start or Path.cwd()).resolve()\n",
    "    # walk up a few levels to find typical repo markers\n",
    "    for _ in range(6):\n",
    "        if (p / \"configs\").exists() and (p / \"src\").exists():\n",
    "            return p\n",
    "        if (p / \"pyproject.toml\").exists() or (p / \"README.md\").exists():\n",
    "            # still require configs to avoid false positives\n",
    "            if (p / \"configs\").exists():\n",
    "                return p\n",
    "        p = p.parent\n",
    "    return Path.cwd().resolve()\n",
    "\n",
    "REPO_ROOT = _find_repo_root()\n",
    "os.chdir(REPO_ROOT)  # ensure relative paths work (configs/, runs/, etc.)\n",
    "\n",
    "print(\"REPO_ROOT:\", REPO_ROOT)\n",
    "\n",
    "# Pick a config:\n",
    "# - For a tiny run: configs/skynet_smoke.yaml\n",
    "# - For a fuller run: configs/skynet_mvp.yaml\n",
    "CFG_PATH = Path(\"configs/skynet_smoke.yaml\")\n",
    "\n",
    "# If your notebook starts in a different working dir, this ensures CFG_PATH is valid:\n",
    "if not CFG_PATH.exists():\n",
    "    alt = (REPO_ROOT / \"configs\" / CFG_PATH.name)\n",
    "    if alt.exists():\n",
    "        CFG_PATH = alt\n",
    "print(\"CFG_PATH:\", CFG_PATH, \"(exists=\", CFG_PATH.exists(), \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2462b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0B — Core imports (kept in one place for restart safety)\n",
    "\n",
    "import json\n",
    "import inspect\n",
    "\n",
    "from inkswarm_detectlab.config import load_config\n",
    "from inkswarm_detectlab.ui.steps import StepRecorder\n",
    "from inkswarm_detectlab.ui.notebook_tools import print_run_tree, tail_text\n",
    "\n",
    "from inkswarm_detectlab.ui.step_runner import (\n",
    "    resolve_run_id,\n",
    "    wire_check,\n",
    "    step_dataset,\n",
    "    step_features,\n",
    "    step_baselines,\n",
    "    step_eval,\n",
    "    step_export,\n",
    ")\n",
    "\n",
    "print(\"Imports OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c4d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0C — User inputs / toggles\n",
    "\n",
    "# If None, run_id is generated from config fingerprint (recommended for ad-hoc runs).\n",
    "# Or set explicitly, e.g.: RUN_ID = \"RR2_MVP_GIT_B_0002\"\n",
    "RUN_ID = None\n",
    "\n",
    "# Per-step policy toggles\n",
    "REUSE_IF_EXISTS = True\n",
    "\n",
    "DO_STEP_1_DATASET = True\n",
    "FORCE_STEP_1_DATASET = False\n",
    "\n",
    "DO_STEP_2_FEATURES = True\n",
    "FORCE_STEP_2_FEATURES = False\n",
    "USE_SHARED_FEATURE_CACHE = True\n",
    "WRITE_SHARED_FEATURE_CACHE = True\n",
    "\n",
    "DO_STEP_3_BASELINES = True\n",
    "FORCE_STEP_3_BASELINES = False  # If outputs already exist, set True.\n",
    "\n",
    "DO_STEP_4_EVAL = True\n",
    "FORCE_STEP_4_EVAL = False\n",
    "\n",
    "DO_STEP_5_EXPORT = True\n",
    "FORCE_STEP_5_EXPORT = False\n",
    "\n",
    "print(\"Toggles loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739f5ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0D — Resolve cfg + run_id\n",
    "\n",
    "cfg, run_id = resolve_run_id(CFG_PATH, run_id=RUN_ID)\n",
    "print(\"cfg_path:\", CFG_PATH)\n",
    "print(\"run_id:\", run_id)\n",
    "\n",
    "# Recorder (records steps when you use the step_* wrappers below)\n",
    "rec = StepRecorder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7331c46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0E — Wiring / paths check (Dry-run)\n",
    "\n",
    "check = wire_check(CFG_PATH, run_id=run_id)\n",
    "print(json.dumps(check, indent=2))\n",
    "\n",
    "rdir = Path(check[\"paths\"][\"run_dir\"])\n",
    "print(\"\\nRun tree (quick):\")\n",
    "print_run_tree(rdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcfb061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: consistent prints for step outcomes\n",
    "\n",
    "def _print_outcome(out):\n",
    "    print(f\"\\n=== STEP: {out.name} ===\")\n",
    "    print(\"status:\", out.status)\n",
    "    print(\"decision:\", f\"{out.decision.mode} — {out.decision.reason}\")\n",
    "    print(\"decision_meta:\", f\"used_manifest={out.decision.used_manifest} forced={out.decision.forced}\")\n",
    "    if out.notes:\n",
    "        print(\"notes:\")\n",
    "        for n in out.notes:\n",
    "            print(\" -\", n)\n",
    "    if out.outputs:\n",
    "        print(\"outputs:\")\n",
    "        for k, a in out.outputs.items():\n",
    "            try:\n",
    "                p = a.get(\"path\")\n",
    "                ex = a.get(\"exists\")\n",
    "                print(f\" - {k}: {p} (exists={ex})\")\n",
    "            except Exception:\n",
    "                print(f\" - {k}: {getattr(a, 'path', '')} (exists={getattr(a, 'exists', None)})\")\n",
    "    if out.summary:\n",
    "        print(\"summary:\", out.summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 — Raw + Dataset (or reuse)\n",
    "\n",
    "out1 = None\n",
    "if DO_STEP_1_DATASET:\n",
    "    out1 = step_dataset(\n",
    "        cfg,\n",
    "        cfg_path=CFG_PATH,\n",
    "        run_id=run_id,\n",
    "        rec=rec,\n",
    "        reuse_if_exists=REUSE_IF_EXISTS,\n",
    "        force=FORCE_STEP_1_DATASET,\n",
    "    )\n",
    "    _print_outcome(out1)\n",
    "else:\n",
    "    print(\"Skipped (DO_STEP_1_DATASET=False)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e2b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1b — Labels + sanity checks (lightweight)\n",
    "\n",
    "from inkswarm_detectlab.synthetic.label_defs import as_markdown_table\n",
    "from inkswarm_detectlab.io.tables import read_auto\n",
    "\n",
    "print(\"\\nLabel definitions (synthetic scenarios):\")\n",
    "print(as_markdown_table())\n",
    "\n",
    "train_path = (rdir / \"dataset\" / \"login_attempt\" / \"train.parquet\")\n",
    "if train_path.exists():\n",
    "    df = read_auto(train_path)\n",
    "    label_cols = [c for c in df.columns if c.startswith(\"label_\")]\n",
    "    print(\"\\nTrain split size:\", len(df))\n",
    "    if label_cols:\n",
    "        print(\"Label prevalence (train):\")\n",
    "        for c in sorted(label_cols):\n",
    "            prev = float(df[c].mean())\n",
    "            print(f\" - {c}: {prev:.4f}\")\n",
    "    else:\n",
    "        print(\"No label_ columns found in dataset table (unexpected).\")\n",
    "else:\n",
    "    print(\"Train split missing; run Step 1 first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06df5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 — Features (or reuse cache/artifacts)\n",
    "#\n",
    "# NOTE: step_features() signature has changed across patches. This cell adapts to what's installed\n",
    "# by inspecting the signature and only passing supported kwargs.\n",
    "\n",
    "import inspect\n",
    "\n",
    "out2 = None\n",
    "if DO_STEP_2_FEATURES:\n",
    "    sig = inspect.signature(step_features)\n",
    "    params = sig.parameters\n",
    "\n",
    "    kwargs = dict(\n",
    "        cfg_path=CFG_PATH,\n",
    "        run_id=run_id,\n",
    "        rec=rec,\n",
    "        reuse_if_exists=REUSE_IF_EXISTS,\n",
    "        force=FORCE_STEP_2_FEATURES,\n",
    "    )\n",
    "\n",
    "    # Shared feature cache toggles (compat across versions)\n",
    "    if \"use_shared_feature_cache\" in params:\n",
    "        kwargs[\"use_shared_feature_cache\"] = USE_SHARED_FEATURE_CACHE\n",
    "    elif \"use_shared_cache\" in params:\n",
    "        kwargs[\"use_shared_cache\"] = USE_SHARED_FEATURE_CACHE\n",
    "    elif \"shared_cache\" in params:\n",
    "        kwargs[\"shared_cache\"] = USE_SHARED_FEATURE_CACHE\n",
    "\n",
    "    if \"write_shared_feature_cache\" in params:\n",
    "        kwargs[\"write_shared_feature_cache\"] = WRITE_SHARED_FEATURE_CACHE\n",
    "    elif \"write_shared_cache\" in params:\n",
    "        kwargs[\"write_shared_cache\"] = WRITE_SHARED_FEATURE_CACHE\n",
    "    elif \"write_cache\" in params:\n",
    "        kwargs[\"write_cache\"] = WRITE_SHARED_FEATURE_CACHE\n",
    "\n",
    "    out2 = step_features(cfg, **kwargs)\n",
    "    _print_outcome(out2)\n",
    "\n",
    "else:\n",
    "    print(\"Skipped (DO_STEP_2_FEATURES=False)\")\n",
    "\n",
    "print(\"step_features signature:\", sig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f5bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 — Baselines (or reuse artifacts)\n",
    "\n",
    "out3 = None\n",
    "if DO_STEP_3_BASELINES:\n",
    "    try:\n",
    "        out3 = step_baselines(\n",
    "            cfg,\n",
    "            cfg_path=CFG_PATH,\n",
    "            run_id=run_id,\n",
    "            rec=rec,\n",
    "            reuse_if_exists=REUSE_IF_EXISTS,\n",
    "            force=FORCE_STEP_3_BASELINES,\n",
    "        )\n",
    "        _print_outcome(out3)\n",
    "\n",
    "        metrics_path = Path(cfg.paths.runs_dir) / run_id / \"models\" / \"login_attempt\" / \"baselines\" / \"metrics.json\"\n",
    "        if metrics_path.exists():\n",
    "            metrics = json.loads(metrics_path.read_text(encoding=\"utf-8\"))\n",
    "            print(\"\\nBaseline summary (meta):\")\n",
    "            print(json.dumps(metrics.get(\"meta\", {}), indent=2))\n",
    "        else:\n",
    "            print(\"\\nmetrics.json not found (ok on partial runs).\")\n",
    "    except FileExistsError as e:\n",
    "        print(\"Baselines output already exists. Set FORCE_STEP_3_BASELINES=True to overwrite.\")\n",
    "        raise\n",
    "else:\n",
    "    print(\"Skipped (DO_STEP_3_BASELINES=False)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 — Eval (slice + stability reports)\n",
    "\n",
    "out4 = None\n",
    "if DO_STEP_4_EVAL:\n",
    "    out4 = step_eval(\n",
    "        cfg,\n",
    "        cfg_path=CFG_PATH,\n",
    "        run_id=run_id,\n",
    "        rec=rec,\n",
    "        reuse_if_exists=REUSE_IF_EXISTS,\n",
    "        force=FORCE_STEP_4_EVAL,\n",
    "    )\n",
    "    _print_outcome(out4)\n",
    "\n",
    "    for rel in [\n",
    "        \"reports/eval_slices_login_attempt.md\",\n",
    "        \"reports/eval_stability_login_attempt.md\",\n",
    "    ]:\n",
    "        p = (Path(cfg.paths.runs_dir) / run_id / rel)\n",
    "        print(f\" - {rel}: {'OK' if p.exists() else 'missing'} ({p})\")\n",
    "else:\n",
    "    print(\"Skipped (DO_STEP_4_EVAL=False)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344733a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 — Export (UI summary + exec summary + UI bundle + handover + optional evidence)\n",
    "\n",
    "out5 = None\n",
    "if DO_STEP_5_EXPORT:\n",
    "    out5 = step_export(\n",
    "        cfg,\n",
    "        cfg_path=CFG_PATH,\n",
    "        run_id=run_id,\n",
    "        rec=rec,\n",
    "        reuse_if_exists=REUSE_IF_EXISTS,\n",
    "        force=FORCE_STEP_5_EXPORT,\n",
    "    )\n",
    "    _print_outcome(out5)\n",
    "\n",
    "    print(\"\\nRun tree (after export):\")\n",
    "    print_run_tree(Path(cfg.paths.runs_dir) / run_id)\n",
    "\n",
    "    # Optional: if evidence bundle exists and you want to run it explicitly, call it safely with run_dir.\n",
    "    try:\n",
    "        from inkswarm_detectlab.share.evidence import export_evidence_bundle\n",
    "        export_evidence_bundle(run_dir=(Path(cfg.paths.runs_dir) / run_id))\n",
    "        print(\"Evidence bundle: OK\")\n",
    "    except Exception as e:\n",
    "        print(\"Evidence bundle skipped:\", e)\n",
    "else:\n",
    "    print(\"Skipped (DO_STEP_5_EXPORT=False)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4b9fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 — Step summary table (shows latest attempt per step)\n",
    "\n",
    "print(rec.to_markdown())\n",
    "\n",
    "# Extra: quick artifact checks for RR\n",
    "rdir2 = Path(cfg.paths.runs_dir) / run_id\n",
    "checks = {\n",
    "    \"EXEC_SUMMARY.md\": (rdir2 / \"reports\" / \"EXEC_SUMMARY.md\").exists(),\n",
    "    \"summary.md\": (rdir2 / \"reports\" / \"summary.md\").exists(),\n",
    "    \"mvp_handover.md\": (rdir2 / \"reports\" / \"mvp_handover.md\").exists(),\n",
    "    \"ui_bundle_dir\": (rdir2 / \"share\" / \"reports\").exists(),\n",
    "}\n",
    "print(\"\\nRR artifact checks:\")\n",
    "for k, v in checks.items():\n",
    "    print(f\" - {k}: {'OK' if v else 'missing'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
