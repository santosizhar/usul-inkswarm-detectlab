{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "289960c0",
   "metadata": {},
   "source": [
    "# Inkswarm DetectLab \u2014 Step Runner Notebook (D-0022)\n",
    "\n",
    "This notebook lets you execute the pipeline **step-by-step** for **`login_attempt`**, while reusing the existing code structure.\n",
    "\n",
    "## Steps (run in order, or selectively)\n",
    "1. **Raw + Dataset** (or reuse)\n",
    "2. **Features** (or reuse / shared-cache restore)\n",
    "3. **Baselines** (or reuse artifacts)\n",
    "4. **Eval** (slice + stability reports)\n",
    "5. **Export** (summary, UI bundle, handover, evidence)\n",
    "\n",
    "## Deep dives (optional)\n",
    "- `02_featurelab_login_attempt.ipynb` \u2014 feature exploration\n",
    "- `03_baselinelab_login_attempt.ipynb` \u2014 baseline exploration\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from inkswarm_detectlab.config import load_config\n",
    "from inkswarm_detectlab.ui.steps import StepRecorder\n",
    "from inkswarm_detectlab.ui.notebook_tools import find_run_dir, print_run_tree, tail_text\n",
    "from inkswarm_detectlab.ui.step_runner import (\n",
    "    resolve_run_id,\n",
    "    wire_check,\n",
    "    step_dataset,\n",
    "    step_features,\n",
    "    step_baselines,\n",
    "    step_eval,\n",
    "    step_export,\n",
    ")\n",
    "\n",
    "# ==========\n",
    "# USER INPUT\n",
    "# ==========\n",
    "\n",
    "# Pick a config. For a tiny run, use:\n",
    "#   configs/skynet_smoke.yaml\n",
    "# For a fuller run:\n",
    "#   configs/skynet_mvp.yaml\n",
    "CFG_PATH = Path(\"configs/skynet_smoke.yaml\")\n",
    "\n",
    "# If None, a run_id is generated from cfg fingerprint.\n",
    "RUN_ID = None  # e.g. \"RUN_SAMPLE_SMOKE_0001\"\n",
    "\n",
    "# Per-step toggles (BQ2=C: explicit manual control)\n",
    "REUSE_IF_EXISTS = True\n",
    "\n",
    "DO_STEP_1_DATASET = True\n",
    "FORCE_STEP_1_DATASET = False\n",
    "\n",
    "DO_STEP_2_FEATURES = True\n",
    "FORCE_STEP_2_FEATURES = False\n",
    "USE_SHARED_FEATURE_CACHE = True\n",
    "WRITE_SHARED_FEATURE_CACHE = True\n",
    "\n",
    "DO_STEP_3_BASELINES = True\n",
    "FORCE_STEP_3_BASELINES = False\n",
    "\n",
    "DO_STEP_4_EVAL = True\n",
    "FORCE_STEP_4_EVAL = False\n",
    "\n",
    "DO_STEP_5_EXPORT = True\n",
    "FORCE_STEP_5_EXPORT = False\n",
    "\n",
    "# ==========\n",
    "# END USER INPUT\n",
    "# ==========\n",
    "\n",
    "cfg, run_id = resolve_run_id(CFG_PATH, run_id=RUN_ID)\n",
    "print(\"cfg_path:\", CFG_PATH)\n",
    "print(\"run_id:\", run_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf57e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0 \u2014 wiring / paths check (Dry-run A)\n",
    "check = wire_check(CFG_PATH, run_id=run_id)\n",
    "print(json.dumps(check, indent=2))\n",
    "rdir = Path(check[\"paths\"][\"run_dir\"])\n",
    "print(\"\\nRun tree (quick):\")\n",
    "print_run_tree(rdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe894ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility for consistent step prints\n",
    "def _print_outcome(out):\n",
    "    print(f\"\\n=== STEP: {out.name} ===\")\n",
    "    print(\"status:\", out.status)\n",
    "    print(\"decision:\", f\"{out.decision.mode} \u2014 {out.decision.reason}\")\n",
    "    if out.notes:\n",
    "        print(\"notes:\")\n",
    "        for n in out.notes:\n",
    "            print(\" -\", n)\n",
    "    if out.outputs:\n",
    "        print(\"outputs:\")\n",
    "        for k, a in out.outputs.items():\n",
    "            try:\n",
    "                p = a.get(\"path\")  # if dict-like\n",
    "                ex = a.get(\"exists\")\n",
    "                print(f\" - {k}: {p} (exists={ex})\")\n",
    "            except Exception:\n",
    "                print(f\" - {k}: {getattr(a, 'path', '')} (exists={getattr(a, 'exists', None)})\")\n",
    "    if out.summary:\n",
    "        print(\"summary:\", out.summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a1541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 \u2014 Raw + Dataset (or reuse)\n",
    "rec = StepRecorder()\n",
    "out1 = None\n",
    "if DO_STEP_1_DATASET:\n",
    "    out1 = step_dataset(\n",
    "        cfg,\n",
    "        cfg_path=CFG_PATH,\n",
    "        run_id=run_id,\n",
    "        rec=rec,\n",
    "        reuse_if_exists=REUSE_IF_EXISTS,\n",
    "        force=FORCE_STEP_1_DATASET,\n",
    "    )\n",
    "    _print_outcome(out1)\n",
    "else:\n",
    "    print(\"Skipped (DO_STEP_1_DATASET=False)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c269a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1b \u2014 Labels + sanity checks (lightweight)\n",
    "# Surfaces label assignment logic (non-random) and basic distributions.\n",
    "from inkswarm_detectlab.synthetic.label_defs import as_markdown_table\n",
    "from inkswarm_detectlab.io.tables import read_auto\n",
    "\n",
    "rdir = find_run_dir(cfg.paths.runs_dir, run_id)\n",
    "\n",
    "print(\"\\nLabel definitions (synthetic scenarios):\")\n",
    "print(as_markdown_table())\n",
    "\n",
    "train_path = (rdir / \"dataset\" / \"login_attempt\" / \"train.parquet\")\n",
    "if train_path.exists():\n",
    "    df = read_auto(train_path)\n",
    "    label_cols = [c for c in df.columns if c.startswith(\"label_\")]\n",
    "    print(\"\\nTrain split size:\", len(df))\n",
    "    if label_cols:\n",
    "        print(\"Label prevalence (train):\")\n",
    "        for c in sorted(label_cols):\n",
    "            prev = float(df[c].mean())\n",
    "            print(f\" - {c}: {prev:.4f}\")\n",
    "    else:\n",
    "        print(\"No label_ columns found in dataset table (unexpected).\")\n",
    "else:\n",
    "    print(\"Train split missing; run Step 1 first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2afa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 \u2014 Features (or reuse / shared-cache restore)\n",
    "out2 = None\n",
    "if DO_STEP_2_FEATURES:\n",
    "    out2 = step_features(\n",
    "        cfg,\n",
    "        cfg_path=CFG_PATH,\n",
    "        run_id=run_id,\n",
    "        rec=rec,\n",
    "        reuse_if_exists=REUSE_IF_EXISTS,\n",
    "        force=FORCE_STEP_2_FEATURES,\n",
    "        use_cache=USE_SHARED_FEATURE_CACHE,\n",
    "        write_cache=WRITE_SHARED_FEATURE_CACHE,\n",
    "    )\n",
    "    _print_outcome(out2)\n",
    "    print(\"\\nLog tail (featurelab):\")\n",
    "    log_path = Path(cfg.paths.runs_dir) / run_id / \"share\" / \"logs\" / \"featurelab.log\"\n",
    "    if log_path.exists():\n",
    "        print(tail_text(log_path, n_lines=120))\n",
    "    else:\n",
    "        print(\"(no featurelab.log yet)\")\n",
    "else:\n",
    "    print(\"Skipped (DO_STEP_2_FEATURES=False)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e52e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 \u2014 Baselines (or reuse artifacts)\n",
    "out3 = None\n",
    "if DO_STEP_3_BASELINES:\n",
    "    out3 = step_baselines(\n",
    "        cfg,\n",
    "        run_id=run_id,\n",
    "        rec=rec,\n",
    "        reuse_if_exists=REUSE_IF_EXISTS,\n",
    "        force=FORCE_STEP_3_BASELINES,\n",
    "        cfg_path=CFG_PATH,\n",
    "    )\n",
    "    _print_outcome(out3)\n",
    "    # Quick look at metrics.json if present\n",
    "    metrics_path = Path(cfg.paths.runs_dir) / run_id / \"models\" / \"login_attempt\" / \"baselines\" / \"metrics.json\"\n",
    "    if metrics_path.exists():\n",
    "        metrics = json.loads(metrics_path.read_text(encoding=\"utf-8\"))\n",
    "        print(\"\\nBaseline summary (meta):\")\n",
    "        print(json.dumps(metrics.get(\"meta\", {}), indent=2))\n",
    "else:\n",
    "    print(\"Skipped (DO_STEP_3_BASELINES=False)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f8532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 \u2014 Eval (slice + stability reports)\n",
    "out4 = None\n",
    "if DO_STEP_4_EVAL:\n",
    "    out4 = step_eval(\n",
    "        cfg,\n",
    "        cfg_path=CFG_PATH,\n",
    "        run_id=run_id,\n",
    "        rec=rec,\n",
    "        reuse_if_exists=REUSE_IF_EXISTS,\n",
    "        force=FORCE_STEP_4_EVAL,\n",
    "    )\n",
    "    _print_outcome(out4)\n",
    "    # Point to key report files\n",
    "    rdir = Path(cfg.paths.runs_dir) / run_id\n",
    "    for rel in [\n",
    "        \"reports/eval_slices_login_attempt.md\",\n",
    "        \"reports/eval_stability_login_attempt.md\",\n",
    "    ]:\n",
    "        p = rdir / rel\n",
    "        print(f\" - {rel}: {'OK' if p.exists() else 'missing'} ({p})\")\n",
    "else:\n",
    "    print(\"Skipped (DO_STEP_4_EVAL=False)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402fc530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 \u2014 Export share bundle (summary + UI bundle + handover + evidence)\n",
    "out5 = None\n",
    "if DO_STEP_5_EXPORT:\n",
    "    out5 = step_export(\n",
    "        cfg,\n",
    "        cfg_path=CFG_PATH,\n",
    "        run_id=run_id,\n",
    "        rec=rec,\n",
    "        reuse_if_exists=REUSE_IF_EXISTS,\n",
    "        force=FORCE_STEP_5_EXPORT,\n",
    "    )\n",
    "    _print_outcome(out5)\n",
    "    print(\"\\nRun tree (after export):\")\n",
    "    print_run_tree(Path(cfg.paths.runs_dir) / run_id)\n",
    "else:\n",
    "    print(\"Skipped (DO_STEP_5_EXPORT=False)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step summary table (D-0022 visibility)\n",
    "print(rec.to_markdown())\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}