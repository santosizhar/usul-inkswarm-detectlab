"""Generate a human-readable RR evidence summary (Markdown).

This is written into journals/ so it can be committed as a small evidence
bundle without committing full run data.
"""

from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import Any, Dict


def _load_json(path: Path) -> Dict[str, Any]:
    return json.loads(path.read_text(encoding="utf-8"))


def _fmt(v: Any) -> str:
    if v is None:
        return "-"
    if isinstance(v, float):
        return f"{v:.6f}"
    return str(v)


def _warn_low_prauc(sig: Dict[str, Any], threshold: float = 0.05) -> str | None:
    models = sig.get("baseline_models") or {}
    low: list[str] = []
    for mname, m in models.items():
        splits = (m or {}).get("splits") or {}
        for split, sm in splits.items():
            pr = (sm or {}).get("pr_auc")
            if pr is not None and float(pr) < threshold:
                low.append(f"{mname}/{split} (pr_auc={float(pr):.4f})")
    if not low:
        return None
    return "Low PR-AUC warning (MVP: warning-only): " + ", ".join(low)


def build_md(base_run_id: str, run_a: str, run_b: str, sig_a: Path, sig_b: Path) -> str:
    sa = _load_json(sig_a)
    sb = _load_json(sig_b)

    lines: list[str] = []
    lines.append(f"# RR Evidence Summary — RR-0001 — {base_run_id}\n")
    lines.append("This file is generated by `scripts/rr_mvp.ps1` / `scripts/rr_mvp.sh`.\n")
    lines.append("## Runs")
    lines.append(f"- Run A: `{run_a}`")
    lines.append(f"- Run B: `{run_b}`\n")
    lines.append("## Determinism sanity check")
    lines.append("- Status: ✅ signatures identical (A == B)\n")

    lines.append("## Key artifacts")
    lines.append(f"- `runs/{run_a}/reports/summary.md`")
    lines.append(f"- `runs/{run_a}/models/login_attempt/baselines/report.md`")
    lines.append(f"- `runs/{run_a}/models/login_attempt/baselines/metrics.json`\n")

    warn = _warn_low_prauc(sa)
    if warn:
        lines.append("## Warnings")
        lines.append(f"- ⚠️ {warn}\n")

    lines.append("## Dataset split sizes (login_attempt)")
    rows = sa.get("login_split_rows") or {}
    lines.append("| split | rows |"); lines.append("|---|---:|")
    for split in ["train", "time_eval", "user_holdout"]:
        lines.append(f"| {split} | {rows.get(split)} |")
    lines.append("")

    lines.append("## Baseline headline metrics")
    lines.append("| model | split | pr_auc | roc_auc | recall@1%FPR |")
    lines.append("|---|---|---:|---:|---:|")
    models = sa.get("baseline_models") or {}
    for model in sorted(models.keys()):
        splits = (models[model] or {}).get("splits") or {}
        for split in ["train", "time_eval", "user_holdout"]:
            sm = splits.get(split) or {}
            lines.append(
                f"| {model} | {split} | {_fmt(sm.get('pr_auc'))} | {_fmt(sm.get('roc_auc'))} | {_fmt(sm.get('recall_at_1pct_fpr'))} |"
            )
    lines.append("")

    lines.append("## How to use the MVP")
    lines.append("See: `docs/mvp_usage.md` (install, run commands, where results live, and how to interpret them).\n")
    lines.append("## Evidence bundle")
    lines.append("The small evidence bundle for this RR run lives under:")
    lines.append(f"- `rr_evidence/RR-0001/{base_run_id}/` (log + signatures)\n")

    return "\n".join(lines).rstrip() + "\n"


def main() -> None:
    ap = argparse.ArgumentParser()
    ap.add_argument("--base-run-id", required=True)
    ap.add_argument("--run-a", required=True)
    ap.add_argument("--run-b", required=True)
    ap.add_argument("--sig-a", required=True)
    ap.add_argument("--sig-b", required=True)
    ap.add_argument("--out", required=True)
    args = ap.parse_args()

    out = Path(args.out)
    out.parent.mkdir(parents=True, exist_ok=True)
    md = build_md(args.base_run_id, args.run_a, args.run_b, Path(args.sig_a), Path(args.sig_b))
    out.write_text(md, encoding="utf-8")


if __name__ == "__main__":
    main()
